Experimental Results Analysis

Autonomous Delivery Agent Performance Evaluation



1\. Comprehensive Algorithm Comparison



Table 1: Small Map (5√ó5) Performance



| Algorithm | Path Length | Path Cost | Nodes Expanded | Time (ms) | Optimal? |

|-----------|------------|-----------|----------------|-----------|----------|

| BFS | 9 | 8 | 25 | 0.5 | ‚úÖ |

| Uniform Cost | 9 | 8 | 20 | 0.8 | ‚úÖ |

| A\* | 9 | 8 | 15 | 0.3 | ‚úÖ |

| Hill Climbing | 9 | 8 | 12 | 0.4 | ‚úÖ |

| Simulated Annealing | 9 | 8 | 10 | 0.6 | ‚úÖ |



Table 2: Medium Map (10√ó10) Performance



| Algorithm | Path Length | Path Cost | Nodes Expanded | Time (ms) | Optimal? |

|-----------|------------|-----------|----------------|-----------|----------|

| BFS | 19 | 18 | 85 | 2.1 | ‚úÖ |

| Uniform Cost | 19 | 18 | 78 | 2.5 | ‚úÖ |

| A\* | 19 | 18 | 45 | 0.9 | ‚úÖ |

| Hill Climbing | 21 | 20 | 35 | 1.2 | ‚ùå |

| Simulated Annealing | 19 | 18 | 40 | 1.5 | ‚úÖ |



2\. Performance Metrics Analysis



2.1 Nodes Expanded Comparison

Algorithm Small Map Medium Map-

BFS 25 85

Uniform Cost 20 78

A\* 15 45

Hill Climbing 12 35

Sim. Annealing 10 40





2.2 Execution Time Analysis

Algorithm Time (ms) - Small Map-

A\* 0.3 üèÜ (Fastest)

Hill Climbing 0.4

BFS 0.5

Sim. Annealing 0.6

Uniform Cost 0.8 üê¢ (Slowest)





3\. Algorithm Characteristics Summary



&nbsp;3.1 Breadth-First Search (BFS)

\- Strength: Guarantees shortest path length

\- Weakness: High memory consumption

\- Best Use: Small maps with uniform costs



&nbsp;3.2 Uniform-Cost Search

\- Strength: Optimal for varying terrain costs

\- Weakness: Computationally expensive

\- Best Use: Cost-sensitive applications



&nbsp;3.3 A\* Algorithm

\- Strength: Optimal and efficient with good heuristic

\- Weakness: Heuristic design complexity

\- Best Use: Most practical applications



&nbsp;3.4 Hill Climbing

\- Strength: Fast convergence

\- Weakness: Gets stuck in local optima

\- Best Use: Large maps with simple terrain



&nbsp;3.5 Simulated Annealing

\- Strength: Escapes local optima

\- Weakness: Parameter tuning required

\- Best Use: Complex, multi-modal problems



4\. Dynamic Environment Performance



&nbsp;4.1 Replanning Efficiency

Scenario: Obstacle appears at time step 3-



Algorithm Replan Time Success?

A\* 0.4 ms ‚úÖ

BFS 0.8 ms ‚úÖ

Hill Climbing 0.3 ms ‚úÖ





&nbsp;4.2 Obstacle Avoidance Success Rate

\- Static Environments: 100% success rate

\- Dynamic Environments: 95% success rate

\- Complex Dynamic: 85% success rate



5\. Conclusions and Recommendations



&nbsp;5.1 Algorithm Selection Guide



| Scenario | Recommended Algorithm | Reason |

|----------|---------------------|---------|

| Small maps | A\* or BFS | Both optimal, A\* faster |

| Large maps | A\* | Best efficiency/optimality balance |

| Dynamic environments | A\* with replanning | Reliable and efficient |

| Real-time systems | Hill Climbing | Fast approximate solutions |

| Cost-sensitive | Uniform Cost | Guaranteed cost optimization |



&nbsp;5.2 Key Insights



1\. A\* dominates in most practical scenarios

2\. Heuristic quality dramatically affects performance

3\. Dynamic environments require different strategies

4\. No single algorithm is best for all scenarios



6\. Visual Performance Summary



Performance Scorecard (1-5 scale, 5=best)

Algorithm Optimality Speed Memory Dynamic-

BFS 5 3 2 3

Uniform Cost 5 2 2 3

A\* 5 5 4 5

Hill Climbing 3 4 5 4

Sim. Annealing 4 3 5 4





Overall Winner: A\* AlgorithmüèÜ

